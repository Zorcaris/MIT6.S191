{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zorcaris/MIT6.S191/blob/main/MitIntroTiDeepLearningLab1Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuPO6g9QZu4t"
      },
      "source": [
        "# Part 2: Music Generation with RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc-kioLVcmed"
      },
      "source": [
        "**2.1 Dependencies**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deF_Rqcibx5v"
      },
      "source": [
        "install Opik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdl_TgfAZbwp",
        "outputId": "e260e3a4-3cf7-4d8f-d605-cac2e05f2f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opik in /usr/local/lib/python3.11/dist-packages (1.6.5)\n",
            "Requirement already satisfied: boto3-stubs>=1.34.110 in /usr/local/lib/python3.11/dist-packages (from boto3-stubs[bedrock-runtime]>=1.34.110->opik) (1.37.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opik) (8.1.8)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from opik) (0.28.1)\n",
            "Requirement already satisfied: levenshtein<1.0.0 in /usr/local/lib/python3.11/dist-packages (from opik) (0.27.1)\n",
            "Requirement already satisfied: litellm in /usr/local/lib/python3.11/dist-packages (from opik) (1.63.11)\n",
            "Requirement already satisfied: openai<2.0.0 in /usr/local/lib/python3.11/dist-packages (from opik) (1.66.3)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from opik) (2.8.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from opik) (2.10.6)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from opik) (8.3.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from opik) (13.9.4)\n",
            "Requirement already satisfied: sentry_sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from opik) (2.22.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (from opik) (9.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opik) (4.67.1)\n",
            "Requirement already satisfied: uuid6 in /usr/local/lib/python3.11/dist-packages (from opik) (2024.7.10)\n",
            "Requirement already satisfied: botocore-stubs in /usr/local/lib/python3.11/dist-packages (from boto3-stubs>=1.34.110->boto3-stubs[bedrock-runtime]>=1.34.110->opik) (1.37.14)\n",
            "Requirement already satisfied: types-s3transfer in /usr/local/lib/python3.11/dist-packages (from boto3-stubs>=1.34.110->boto3-stubs[bedrock-runtime]>=1.34.110->opik) (0.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from boto3-stubs>=1.34.110->boto3-stubs[bedrock-runtime]>=1.34.110->opik) (4.12.2)\n",
            "Requirement already satisfied: mypy-boto3-bedrock-runtime<1.38.0,>=1.37.0 in /usr/local/lib/python3.11/dist-packages (from boto3-stubs[bedrock-runtime]>=1.34.110->opik) (1.37.7)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from levenshtein<1.0.0->opik) (3.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0->opik) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0->opik) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0->opik) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0->opik) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->opik) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->opik) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->opik) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->opik) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->opik) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->opik) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.0.0->opik) (1.0.1)\n",
            "Requirement already satisfied: urllib3>=1.26.11 in /usr/local/lib/python3.11/dist-packages (from sentry_sdk>=2.0.0->opik) (2.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm->opik) (3.11.13)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm->opik) (8.6.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm->opik) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm->opik) (4.23.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm->opik) (0.9.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm->opik) (0.21.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->opik) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytest->opik) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->opik) (1.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->opik) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->opik) (2.18.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm->opik) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm->opik) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (0.23.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->opik) (0.1.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm->opik) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm->opik) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm->opik) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm->opik) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm->opik) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm->opik) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm->opik) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm->opik) (1.18.3)\n",
            "Requirement already satisfied: types-awscrt in /usr/local/lib/python3.11/dist-packages (from botocore-stubs->boto3-stubs>=1.34.110->boto3-stubs[bedrock-runtime]>=1.34.110->opik) (0.24.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm->opik) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm->opik) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm->opik) (2024.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm->opik) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm->opik) (3.4.1)\n"
          ]
        }
      ],
      "source": [
        "pip install opik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "OB21GqZPcKNu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "507173b7-7b90-439d-f875-9548ac956382"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Please enable GPU from runtime settings",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-bef1daae0a0a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Check that we are using a GPU, if not switch runtimes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#   using Runtime > Change Runtime Type > GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Please enable GPU from runtime settings\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mCOMET_API_KEY\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"5pRrCPUHXvzzamH3aErnJ1Fqt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Please insert your Comet API Key\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Please enable GPU from runtime settings"
          ]
        }
      ],
      "source": [
        "!pip install comet_ml > /dev/null 2>&1\n",
        "import comet_ml\n",
        "# TODO: ENTER YOUR API KEY HERE!! instructions above\n",
        "COMET_API_KEY = \"\"\n",
        "\n",
        "# Import PyTorch and other relevant libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Download and import the MIT Introduction to Deep Learning package\n",
        "!pip install mitdeeplearning --quiet\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "# Import all remaining packages\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import functools\n",
        "from IPython import display as ipythondisplay\n",
        "from tqdm import tqdm\n",
        "from scipy.io.wavfile import write\n",
        "!apt-get install abcmidi timidity > /dev/null 2>&1\n",
        "\n",
        "\n",
        "# Check that we are using a GPU, if not switch runtimes\n",
        "#   using Runtime > Change Runtime Type > GPU\n",
        "assert torch.cuda.is_available(), \"Please enable GPU from runtime settings\"\n",
        "assert COMET_API_KEY != \"5pRrCPUHXvzzamH3aErnJ1Fqt\", \"Please insert your Comet API Key\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyvjUBszfq_K"
      },
      "source": [
        "**2.2 Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2ZBgg9IfnzK"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "songs = mdl.lab1.load_training_data()\n",
        "\n",
        "# Print one of the songs to inspect it in greater detail!\n",
        "example_song = songs[0]\n",
        "print(\"\\nExample song: \")\n",
        "print(example_song)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ0mBoFbf6WW"
      },
      "outputs": [],
      "source": [
        "# Convert the ABC notation to audio file and listen to it\n",
        "mdl.lab1.play_song(example_song)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbVsvWwlgs9f"
      },
      "outputs": [],
      "source": [
        "# Join our list of song strings into a single string containing all songs\n",
        "songs_joined = \"\\n\\n\".join(songs)\n",
        "\n",
        "# Find all unique characters in the joined string\n",
        "vocab = sorted(set(songs_joined))\n",
        "print(\"There are\", len(vocab), \"unique characters in the dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfZMxfjRgz0e"
      },
      "source": [
        "**2.3 Process the dataset for the learning task**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "1P2pDx7og3sY",
        "outputId": "a22181df-e2c5-4914-95fe-66ac0863cd96"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'vocab' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-b90ea7113ed9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# For example, to get the index of the character \"d\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#   we can evaluate `char2idx[\"d\"]`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mchar2idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Create a mapping from indices to characters. This is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
          ]
        }
      ],
      "source": [
        "### Define numerical representation of text ###\n",
        "\n",
        "# Create a mapping from character to unique index.\n",
        "# For example, to get the index of the character \"d\",\n",
        "#   we can evaluate `char2idx[\"d\"]`.\n",
        "char2idx = {u: i for i, u in enumerate(vocab)}\n",
        "\n",
        "# Create a mapping from indices to characters. This is\n",
        "#   the inverse of char2idx and allows us to convert back\n",
        "#   from unique index to the character in our vocabulary.\n",
        "idx2char = np.array(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uYLm080ycFK"
      },
      "outputs": [],
      "source": [
        "print('{')\n",
        "for char, _ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "3jlSZCZqygdb",
        "outputId": "a836692c-b08d-450c-9390-e4d1a9186217"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'songs_joined' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-2aaa90c308fc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mvectorized_songs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msongs_joined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'songs_joined' is not defined"
          ]
        }
      ],
      "source": [
        "### Vectorize the songs string ###\n",
        "\n",
        "'''TODO: Write a function to convert the all songs string to a vectorized\n",
        "    (i.e., numeric) representation. Use the appropriate mapping\n",
        "    above to convert from vocab characters to the corresponding indices.\n",
        "\n",
        "  NOTE: the output of the `vectorize_string` function\n",
        "  should be a np.array with `N` elements, where `N` is\n",
        "  the number of characters in the input string\n",
        "'''\n",
        "def vectorize_string(string):\n",
        "  vectorize = np.array([char2idx[char] for char in string])\n",
        "  return vectorize\n",
        "\n",
        "vectorized_songs = vectorize_string(songs_joined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "Zg2cLeUiyoDk",
        "outputId": "820f2c71-140a-4502-a1e1-08177f622f12"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'songs_joined' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-20ec6e4d1ade>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'{} ---- characters mapped to int ----> {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msongs_joined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorized_songs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# check that vectorized_songs is a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_songs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"returned result should be a numpy array\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'songs_joined' is not defined"
          ]
        }
      ],
      "source": [
        "print ('{} ---- characters mapped to int ----> {}'.format(repr(songs_joined[:10]), vectorized_songs[:10]))\n",
        "# check that vectorized_songs is a numpy array\n",
        "assert isinstance(vectorized_songs, np.ndarray), \"returned result should be a numpy array\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "7Maa6zw3z3d8",
        "outputId": "d5b7b043-05ce-461a-f4bb-1b94084c5a9a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'vectorized_songs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0bc7b7eb73a7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Perform some simple tests to make sure your batch function is working properly!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtest_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvectorized_songs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x_batch shape is incorrect\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vectorized_songs' is not defined"
          ]
        }
      ],
      "source": [
        "### Batch definition to create training examples ###\n",
        "\n",
        "def get_batch(vectorized_songs, seq_length, batch_size):\n",
        "    # the length of the vectorized songs string\n",
        "    n = vectorized_songs.shape[0] - 1\n",
        "    # randomly choose the starting indices for the examples in the training batch\n",
        "    idx = np.random.choice(n - seq_length, batch_size)\n",
        "\n",
        "    '''TODO: construct a list of input sequences for the training batch'''\n",
        "    input_batch =[vectorized_songs[i : i+seq_length] for i in idx]\n",
        "\n",
        "    '''TODO: construct a list of output sequences for the training batch'''\n",
        "    output_batch = [vectorized_songs[i+1 : i+seq_length+1] for i in idx]\n",
        "\n",
        "    # Convert the input and output batches to tensors\n",
        "    x_batch = torch.tensor(input_batch, dtype=torch.long)\n",
        "    y_batch = torch.tensor(output_batch, dtype=torch.long)\n",
        "\n",
        "    return x_batch, y_batch\n",
        "\n",
        "# Perform some simple tests to make sure your batch function is working properly!\n",
        "test_args = (vectorized_songs, 10, 2)\n",
        "x_batch, y_batch = get_batch(*test_args)\n",
        "assert x_batch.shape == (2, 10), \"x_batch shape is incorrect\"\n",
        "assert y_batch.shape == (2, 10), \"y_batch shape is incorrect\"\n",
        "print(\"Batch function works correctly!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "EQ7yrYGYz781",
        "outputId": "6a0cbee9-9fe8-41fb-be23-c186aa2e3071"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'get_batch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-598adfea505e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_songs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step {:3d}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  input: {} ({:s})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx2char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_batch' is not defined"
          ]
        }
      ],
      "source": [
        "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
        "\n",
        "for i, (input_idx, target_idx) in enumerate(zip(x_batch[0], y_batch[0])):\n",
        "    print(\"Step {:3d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx.item()])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx.item()])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT5WvCAjdVy-"
      },
      "source": [
        "**2.4 The Recurrent Neural Network (RNN) model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OEoO3mdqdSLY"
      },
      "outputs": [],
      "source": [
        "### Defining the RNN Model ###\n",
        "\n",
        "'''TODO: Add LSTM and Linear layers to define the RNN model using nn.Module'''\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Define each of the network layers\n",
        "        # Layer 1: Embedding layer to transform indices into dense vectors\n",
        "        #   of a fixed embedding size\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "\n",
        "        '''TODO: Layer 2: LSTM with hidden_size `hidden_size`. note: number of layers defaults to 1.\n",
        "         Use the nn.LSTM() module from pytorch.'''\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True) # TODO\n",
        "\n",
        "        '''TODO: Layer 3: Linear (fully-connected) layer that transforms the LSTM output\n",
        "        #   into the vocabulary size.'''\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size) # TODO\n",
        "\n",
        "    def init_hidden(self, batch_size, device):\n",
        "        # Initialize hidden state and cell state with zeros\n",
        "        return (torch.zeros(1, batch_size, self.hidden_size).to(device),\n",
        "                torch.zeros(1, batch_size, self.hidden_size).to(device))\n",
        "\n",
        "    def forward(self, x, state=None, return_state=False):\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        if state is None:\n",
        "            state = self.init_hidden(x.size(0), x.device)\n",
        "        out, state = self.lstm(x, state)\n",
        "\n",
        "        out = self.fc(out)\n",
        "        return out if not return_state else (out, state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "AWxzJEYypumt",
        "outputId": "a2d3486f-6686-4ea3-e6b3-af6737e3106a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'vocab' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-729628064be2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instantiate the model! Build a simple model with default hyperparameters. You\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#     will get the chance to change these later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
          ]
        }
      ],
      "source": [
        "# Instantiate the model! Build a simple model with default hyperparameters. You\n",
        "#     will get the chance to change these later.\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "hidden_size = 1024\n",
        "batch_size = 8\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = LSTMModel(vocab_size, embedding_dim, hidden_size).to(device)\n",
        "\n",
        "# print out a summary of the model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "0WKQsE5urfR8",
        "outputId": "1c3a02c5-7d59-456c-b3be-d6e922622269"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'get_batch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-38d0f20a55da>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test the model with some sample data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_songs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_batch' is not defined"
          ]
        }
      ],
      "source": [
        "# Test the model with some sample data\n",
        "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\n",
        "x = x.to(device)\n",
        "y = y.to(device)\n",
        "\n",
        "pred = model(x)\n",
        "print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
        "print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "vkW6_WbMtE-Z",
        "outputId": "ea4ba2d4-33eb-41c0-92d2-50a400f3753a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pred' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1e5a22ee8d0f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msampled_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msampled_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampled_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msampled_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
          ]
        }
      ],
      "source": [
        "sampled_indices = torch.multinomial(torch.softmax(pred[0], dim=-1), num_samples=1)\n",
        "sampled_indices = sampled_indices.squeeze(-1).cpu().numpy()\n",
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "EsIQvFlotIp6",
        "outputId": "360c0ef5-8e1a-4309-cfd7-2bb4d09a3e00"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'idx2char' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c7894be80397>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx2char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Next Char Predictions: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx2char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msampled_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'idx2char' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[x[0].cpu()])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKraB9PStTCO"
      },
      "source": [
        "**2.5 Training the model: loss and training operations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "As7X9193tWFq"
      },
      "outputs": [],
      "source": [
        "### Defining the loss function ###\n",
        "\n",
        "# '''TODO: define the compute_loss function to compute and return the loss between\n",
        "#     the true labels and predictions (logits). '''\n",
        "cross_entropy = nn.CrossEntropyLoss() # instantiates the function\n",
        "def compute_loss(labels, logits):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      labels: (batch_size, sequence_length)\n",
        "      logits: (batch_size, sequence_length, vocab_size)\n",
        "\n",
        "    Output:\n",
        "      loss: scalar cross entropy loss over the batch and sequence length\n",
        "    \"\"\"\n",
        "\n",
        "    # Batch the labels so that the shape of the labels should be (B * L,)\n",
        "    batched_labels = labels.view(-1)\n",
        "\n",
        "    ''' TODO: Batch the logits so that the shape of the logits should be (B * L, V) '''\n",
        "    batched_logits = logits.view(-1, logits.shape[-1])\n",
        "\n",
        "    '''TODO: Compute the cross-entropy loss using the batched  next characters and predictions'''\n",
        "    loss =  cross_entropy(batched_logits, batched_labels)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "SiM-Klcj3qsC",
        "outputId": "d235216c-fbf3-494f-f79c-6fd33a4935d5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4b6eecff7b75>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### compute the loss on the predictions from the untrained model from earlier. ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m  \u001b[0;31m# (batch_size, sequence_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m  \u001b[0;31m# (batch_size, sequence_length, vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m '''TODO: compute the loss using the true next characters from the example batch\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ],
      "source": [
        "### compute the loss on the predictions from the untrained model from earlier. ###\n",
        "y.shape  # (batch_size, sequence_length)\n",
        "pred.shape  # (batch_size, sequence_length, vocab_size)\n",
        "\n",
        "'''TODO: compute the loss using the true next characters from the example batch\n",
        "    and the predictions from the untrained model several cells above'''\n",
        "example_batch_loss = compute_loss(y, pred) # TODO\n",
        "\n",
        "print(f\"Prediction shape: {pred.shape} # (batch_size, sequence_length, vocab_size)\")\n",
        "print(f\"scalar_loss:      {example_batch_loss.mean().item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "IbN3DKeo4smk",
        "outputId": "0fecebb1-d4e1-44b1-ae68-d50c5b3933f9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'vocab' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7b85c2385e31>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Hyperparameter setting and optimization ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Model parameters:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
          ]
        }
      ],
      "source": [
        "### Hyperparameter setting and optimization ###\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Model parameters:\n",
        "params = dict(\n",
        "  num_training_iterations = 3000,  # Increase this to train longer\n",
        "  batch_size = 8,  # Experiment between 1 and 64\n",
        "  seq_length = 100,  # Experiment between 50 and 500\n",
        "  learning_rate = 5e-3,  # Experiment between 1e-5 and 1e-1\n",
        "  embedding_dim = 256,\n",
        "  hidden_size = 1024,  # Experiment between 1 and 2048\n",
        ")\n",
        "\n",
        "# Checkpoint location:\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZDW_nU6D415X"
      },
      "outputs": [],
      "source": [
        "### Create a Comet experiment to track our training run ###\n",
        "\n",
        "def create_experiment():\n",
        "  # end any prior experiments\n",
        "  if 'experiment' in locals():\n",
        "    experiment.end()\n",
        "\n",
        "  # initiate the comet experiment for tracking\n",
        "  experiment = comet_ml.Experiment(\n",
        "                  api_key=COMET_API_KEY,\n",
        "                  project_name=\"6S191_Lab1_Part2\")\n",
        "  # log our hyperparameters, defined above, to the experiment\n",
        "  for param, value in params.items():\n",
        "    experiment.log_parameter(param, value)\n",
        "  experiment.flush()\n",
        "\n",
        "  return experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "N91om__05BH-",
        "outputId": "115abddf-9529-4e62-dc55-3a03345f1b0a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'LSTMModel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4a877d6b2e27>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m '''TODO: instantiate a new LSTMModel model for training using the hyperparameters\n\u001b[1;32m      4\u001b[0m     created above.'''\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embedding_dim\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hidden_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# model = LSTMModel('''TODO: arguments''')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LSTMModel' is not defined"
          ]
        }
      ],
      "source": [
        "### Define optimizer and training operation ###\n",
        "\n",
        "'''TODO: instantiate a new LSTMModel model for training using the hyperparameters\n",
        "    created above.'''\n",
        "model = LSTMModel(vocab_size, params[\"embedding_dim\"], params[\"hidden_size\"])\n",
        "# model = LSTMModel('''TODO: arguments''')\n",
        "\n",
        "# Move the model to the GPU\n",
        "model.to(device)\n",
        "\n",
        "'''TODO: instantiate an optimizer with its learning rate.\n",
        "  Checkout the PyTorch website for a list of supported optimizers.\n",
        "  https://pytorch.org/docs/stable/optim.html\n",
        "  Try using the Adam optimizer to start.'''\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=params[\"learning_rate\"])\n",
        "# optimizer = # TODO\n",
        "\n",
        "def train_step(x, y):\n",
        "  # Set the model's mode to train\n",
        "  model.train()\n",
        "\n",
        "  # Zero gradients for every step\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # Forward pass\n",
        "  '''TODO: feed the current input into the model and generate predictions'''\n",
        "  y_hat = model(x) # TODO\n",
        "  # y_hat = model('''TODO''')\n",
        "\n",
        "  # Compute the loss\n",
        "  '''TODO: compute the loss!'''\n",
        "  loss = compute_loss(y, y_hat) # TODO\n",
        "  # loss = compute_loss('''TODO''', '''TODO''')\n",
        "\n",
        "  # Backward pass\n",
        "  '''TODO: complete the gradient computation and update step.\n",
        "    Remember that in PyTorch there are two steps to the training loop:\n",
        "    1. Backpropagate the loss\n",
        "    2. Update the model parameters using the optimizer\n",
        "  '''\n",
        "  loss.backward() # TODO\n",
        "  optimizer.step() # TODO\n",
        "\n",
        "  return loss\n",
        "\n",
        "##################\n",
        "# Begin training!#\n",
        "##################\n",
        "\n",
        "history = []\n",
        "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\n",
        "experiment = create_experiment()\n",
        "\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
        "for iter in tqdm(range(params[\"num_training_iterations\"])):\n",
        "\n",
        "    # Grab a batch and propagate it through the network\n",
        "    x_batch, y_batch = get_batch(vectorized_songs, params[\"seq_length\"], params[\"batch_size\"])\n",
        "\n",
        "    # Convert numpy arrays to PyTorch tensors\n",
        "    x_batch = torch.tensor(x_batch, dtype=torch.long).to(device)\n",
        "    y_batch = torch.tensor(y_batch, dtype=torch.long).to(device)\n",
        "\n",
        "    # Take a train step\n",
        "    loss = train_step(x_batch, y_batch)\n",
        "\n",
        "    # Log the loss to the Comet interface\n",
        "    experiment.log_metric(\"loss\", loss.item(), step=iter)\n",
        "\n",
        "    # Update the progress bar and visualize within notebook\n",
        "    history.append(loss.item())\n",
        "    plotter.plot(history)\n",
        "\n",
        "    # Save model checkpoint\n",
        "    if iter % 100 == 0:\n",
        "        torch.save(model.state_dict(), checkpoint_prefix)\n",
        "\n",
        "# Save the final trained model\n",
        "torch.save(model.state_dict(), checkpoint_prefix)\n",
        "experiment.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8_itSYE_72n"
      },
      "source": [
        "**2.6 Generate music using the RNN model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Prediction of a generated song ###\n",
        "\n",
        "def generate_text(model, start_string, generation_length=1000):\n",
        "  # Evaluation step (generating ABC text using the learned RNN model)\n",
        "\n",
        "  '''TODO: convert the start string to numbers (vectorize)'''\n",
        "  input_idx = ['''TODO'''] # TODO\n",
        "  input_idx = torch.tensor([input_idx], dtype=torch.long).to(device)\n",
        "\n",
        "  # Initialize the hidden state\n",
        "  state = model.init_hidden(input_idx.size(0), device)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "  tqdm._instances.clear()\n",
        "\n",
        "  for i in tqdm(range(generation_length)):\n",
        "    '''TODO: evaluate the inputs and generate the next character predictions'''\n",
        "    predictions, hidden_state = model('''TODO''', '''TODO''', return_state=True) # TODO\n",
        "\n",
        "    # Remove the batch dimension\n",
        "    predictions = predictions.squeeze(0)\n",
        "\n",
        "    '''TODO: use a multinomial distribution to sample over the probabilities'''\n",
        "    input_idx = torch.multinomial('''TODO''', dim=-1), num_samples=1) # TODO\n",
        "\n",
        "    '''TODO: add the predicted character to the generated text!'''\n",
        "    # Hint: consider what format the prediction is in vs. the output\n",
        "    text_generated.append('''TODO''') # TODO\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "PN5KheU_Y-C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''TODO: Use the model and the function defined above to generate ABC format text of length 1000!\n",
        "    As you may notice, ABC files start with \"X\" - this may be a good start string.'''\n",
        "generated_text = generate_text('''TODO''', '''TODO''', '''TODO''') # TODO"
      ],
      "metadata": {
        "id": "khEkt7EZZFxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Play back generated songs ###\n",
        "\n",
        "generated_songs = mdl.lab1.extract_song_snippet(generated_text)\n",
        "\n",
        "for i, song in enumerate(generated_songs):\n",
        "  # Synthesize the waveform from a song\n",
        "  waveform = mdl.lab1.play_song(song)\n",
        "\n",
        "  # If its a valid song (correct syntax), lets play it!\n",
        "  if waveform:\n",
        "    print(\"Generated song\", i)\n",
        "    ipythondisplay.display(waveform)\n",
        "\n",
        "    numeric_data = np.frombuffer(waveform.data, dtype=np.int16)\n",
        "    wav_file_path = f\"output_{i}.wav\"\n",
        "    write(wav_file_path, 88200, numeric_data)\n",
        "\n",
        "    # save your song to the Comet interface -- you can access it there\n",
        "    experiment.log_asset(wav_file_path)"
      ],
      "metadata": {
        "id": "6s0qAEaTZHsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# when done, end the comet experiment\n",
        "experiment.end()"
      ],
      "metadata": {
        "id": "E_41w22_ZJ8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.7 Experiment and get awarded for the best songs!**"
      ],
      "metadata": {
        "id": "6pK1E_a9ZN75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#maybe"
      ],
      "metadata": {
        "id": "bzPV6CtLZQx8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMulUL0IKIbMSiKNnN0h7nt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}